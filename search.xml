<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>hey!你好哇！</title>
    <url>/2022/07/03/My-New-Post/</url>
    <content><![CDATA[<p>兜兜转转，又有了一个稳定的记录平台。</p>
<p>从高中起就陆陆续续换过好多平台想要记录些什么，但是发长文blog的习惯是一直没有养成过，本来不是仔细的性格，记录和维护属实又是很累的事儿，文件夹和各种便签也就越积累越多了。</p>
<p>但是最近一些年好像真的有遇到很多人，也发生了很多事，同时还系统的学习了很多东西（当然更多的是准备），多了好多值得记录的人事物，隐约意识到了规整总结和保存的重要性。</p>
<p>恰逢本科毕业一周年，也刚刚送别了研三毕业的师兄师姐，赶着这么个复杂的心态开始试着以更有条理的方式进入研二生活，因此就有了这个blog。</p>
<p>走马观花的做了好多事，是时候沉下心来啦。</p>
<p>躲不掉的话，那就勇敢面对吧！</p>
]]></content>
      <tags>
        <tag>“杂记”</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2022/07/03/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>榆林反思0813</title>
    <url>/2022/08/13/sx220813/</url>
    <content><![CDATA[<p>从榆林回来了，忙忙碌碌许久，中途也发生了好多乱七八糟的事情，记录一下啦。</p>
<p>啊很奇怪说起来，其实是满心欢喜去的榆林呢。我原以为的集中一批人的精力做一件事应当是很快乐且有收获的，我也一直期待这样的过程，但事实上并没有。在此反思。</p>
<ol>
<li><p>关于统战。统战确实是相当重要的一件事吧，一件事情，九个人朝着共同快乐的地方做了，那就是共同快乐的，五五分朝着两个目的走了那必然是数不清数不清的矛盾。但是确实又是个困难的事儿，尽可能的让每个人都有实打实的驱动进入，在筛选阶段和处理问题阶段都是极大的挑战。但至少，做什么，怎么做，谁来做，做到什么程度，这些基础事项应当是有碰头和共同认可的。</p>
</li>
<li><p>关于沟通。沟通是合作的基础，遇到了很多话不能讲的情况，结果要么耽误事情要么得罪人，应当采纳更有效的解决方案的。沟通的前提首先是要合理和平等，这一点我一向擅长，其次是要逐渐建立起一个坚定的核心，不能总被这样也行那样也行影响了，这一点我仍需加强。沟通不畅对人的消耗真的是，放在生活上就是没有安排的24小时随时待命以及突如其来的换酒店，放在工作上大概是各种各样的需求不匹配 and 你们是不是不沟通啊，难顶。</p>
</li>
<li><p>关于立场。工地（社会）真的确实是很不一样的地方啊，像是纷纷过客匆匆相识又挥一挥衣袖离开，各式各样的人里，小心翼翼、热情、谨慎的外壳和底色太多了，所谓路过的都是人生。要学习的话，一个是我应当要学会找到个人在场景中的定位，一个是要训练一下自己脱离定位的能力。</p>
</li>
<li><p>关于接纳。还知道了一些原来不知道的事情，我大概是个很害怕被八卦甚至是谣言推着走的人，所以一直以来都不太会把自己的事情让大家知道，但是就导致了一些误解或者无奈。一些原以为相对亲近的人在我做事不够妥当的时候埋怨和责怪我，但是也有一些本以为只是普通同学的人在努力的带我快乐起来，还有一些我以为不会接纳这样的我的朋友们，装作不知情的支撑起了我当时百分之八十的快乐，感谢并且会一直记着。</p>
<p>呜，原定要做的事没做完，原定要看的书没看完，但是学到了很多生活经验（并不主观意义上的想），想通了很多事(真好)。总之，那么，new life~</p>
</li>
</ol>
]]></content>
      <tags>
        <tag>“杂记”</tag>
      </tags>
  </entry>
  <entry>
    <title>从有解的模型开始</title>
    <url>/2022/08/14/ky0814/</url>
    <content><![CDATA[<p>在对能量流&#x2F;物质流等各种流耦合的初期建模和测试阶段，很容易面临无解的情况，这种情况在现实中是存在的（总不能任何事情都能靠调度解决吧），但是测试时一个存在的解又是很重要的参考。</p>
<p>为了解决上述问题，有两种改变可以考虑，全连接图或者考虑边界外的出口：</p>
<ol>
<li>全连接图式：想这个起因是一个师兄让考虑一下的一个证明，讲的是物流行业内全连接节点配置（至少是任何两个节点之间都有路径可以流通的配置）对于负载的柔性是最大的，那么一个好的基础模型是否应当是全连接图式的呢？等有空了可以做一下。但是无论是否效果够好，我们都可以用一个基础的全连接图式模型跑代码，再一条条加节点&#x2F;边的各类约束，也许从而会获得一些信息？</li>
<li>模型几乎不会1v1复刻真是系统的，总得定些边界，例如电热耦合的生产，弃电和弃热在现实生活中会以风冷或者直接排出等方式解决掉，但是往往不在我之前的模型中考虑。但是这种强耦合又会导致模型的不可解但实际的可解，在建模的测试阶段应当充分考虑这些因素。</li>
</ol>
]]></content>
      <tags>
        <tag>“科研”</tag>
      </tags>
  </entry>
  <entry>
    <title>图神经网络</title>
    <url>/2022/08/14/ky0814%E2%80%94%E2%80%942/</url>
    <content><![CDATA[<p>随着机器学习、深度学习的发展，语音、图像、自然语言处理逐渐取得了很大的突破，然而语音、图像、文本都是很简单的序列或者网格数据，是很结构化的数据，深度学习很善于处理该种类型的数据。然而现实世界中并不是所有的事物都可以表示成一个序列或者一个网格，例如社交网络、知识图谱、复杂的文件系统等，也就是说很多事物都是非结构化的。因此，对图神经网络的研究也日渐增加。可以把图神经网络分为了五类：图卷积网络、图注意力网络、图自编码机、图生成网络和图时空网络。同时，图分析任务可以大致抽象为以下四类：节点分类、链接预测、聚类以及可视化。</p>
<h2 id="图嵌入"><a href="#图嵌入" class="headerlink" title="图嵌入"></a>图嵌入</h2><p>图嵌入指的是将图转换到保存图信息的低维空间，将图表示为或多组低维向量。图嵌入的输出是表示整个图或者部分图的低维向量。然后将输出的低维向量应用到其他机器学习方法中。 自从word2vec这个神奇的算法出世以后，导致了一波嵌入（Embedding）热，基于句子、文档表达的word2vec、doc2vec算法，基于物品序列的item2vec算法，基于图模型的图嵌入技术，无论是在引荐、广告还是反欺诈范畴，各互联网公司基于本身业务与嵌入结合的论文相继问世。由于图（Graph）表示一种“二维”的关系，而序列（Sequence）表示一种“一维”的关系。因此，要将图转换为Graph Embedding，一般需要先通过一些算法把图变为序列；然后通过一些模型或算法把这些序列转换为Embedding。当前比较知名的图嵌入方法有DeepWalk、Line和Node2vec，这些都是基于顶点对相似度的图表示学习，仅仅保留了一部分的图的特性，其效果类似于按概率的聚类。</p>
<h2 id="图卷积网络"><a href="#图卷积网络" class="headerlink" title="图卷积网络"></a>图卷积网络</h2><p>由传统的卷积神经网络引申出的图卷积网络，图卷积方法可分为两种，基于频谱的方法和基于空间的方法。基于频谱的方法，从图信号处理的角度，引入滤波器来定义图卷积，因此基于频谱的图卷积可理解为从图信号中去除噪声。基于空间的图卷积方法，通过汇集邻居节点的信息来构建图卷积。当图卷积在节点级运作时，可以将图池化模块和图卷积进行交错叠加，从而将图粗化为高级的子图。</p>
<p>在基于空间的图卷积网络中，与传统卷积神经网络相同的是，二者均通过聚合临近的点&#x2F;临近的节点来得到新的层&#x2F;节点表示，即抽象出的表示，以支持下一步的分类、预测等任务。其中，基于递归的空间图卷及网络主要用于不断进行节点间信息交互以更新节点，直至各节点稳定，基于组合的空间图卷及网络主要用于层层分析临域信息以获得总览的效果。而图卷积的关键就在于如何汇集节点自身的特征和临接节点的特征（神经网络学习目标）。</p>
<h2 id="GraphSAGE"><a href="#GraphSAGE" class="headerlink" title="GraphSAGE"></a>GraphSAGE</h2><p>图卷积网络存在的一大问题在于其训练时需要整张图的结构信息，包括训练集和测试集，但是这是对于下一步的分类、预测任务是不利的，因此，我们需要一种方法，合理的把训练集和测试集区分出来，同时适应了网络结构信息不全时的预测问题。这方面的典型应用是GraphSAGE，它的训练主要分为两个步骤：采样和聚合，即首先对节点k的邻居进行采样，接着聚合邻居的信息以更新自身的表示。</p>
<p>对于有监督学习，以预测和真实的交叉熵作为损失函数；对于无监督学习，假设相邻节点的表示尽可能相同来设计损失函数。</p>
]]></content>
      <tags>
        <tag>“科研”</tag>
      </tags>
  </entry>
  <entry>
    <title>超图基础</title>
    <url>/2022/08/14/ky0814%E2%80%94%E2%80%943/</url>
    <content><![CDATA[<p>与普通图不同的是，超图中的边可以连接多个节点，其优势在于可以描述两个节点的图不便于表示的属性及群组关系。</p>
<h2 id="超图描述"><a href="#超图描述" class="headerlink" title="超图描述"></a>超图描述</h2><p>常见的图关联矩阵的行列均为节点；超图的关联矩阵的行为节点，列为超边。同时，超图还可以通过直接拼接超边关联矩阵来融合多模态数据。</p>
<p><img  src="/./images/ky0814-3/image-20220814155201001.png"  ><span class="image-caption">image-20220814155201001</span></p>
<h2 id="HGNN框架"><a href="#HGNN框架" class="headerlink" title="HGNN框架"></a>HGNN框架</h2><p>HGNN框架如下图所示，多模态数据集分为训练数据和测试数据，每个数据包含几个具有特征的节点。然后利用多模态数据集的复杂相关性构造多个超边结构群。将超图的邻域矩阵H和节点特征输入到HGNN中，得到节点输出标签。</p>
<p><img  src="/./images/ky0814-3/image-20220814161234534.png"  ><span class="image-caption">image-20220814161234534</span></p>
<h2 id="网络实现"><a href="#网络实现" class="headerlink" title="网络实现"></a>网络实现</h2><p>HGNN的实现分为以下步骤：构建超图，生成超边特征，更新节点特征。其学习过程包括：输入第L层特征，构建第L层超图结构，超图卷积（包括点卷积和超边卷积），输出L+1层特征。</p>
<p><img  src="/./images/ky0814-3/image-20220814162939272.png"  ><span class="image-caption">image-20220814162939272</span></p>
]]></content>
      <tags>
        <tag>图神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>gurobi数值问题</title>
    <url>/2022/10/12/ky20221012/</url>
    <content><![CDATA[<p>起因是跑代码时出现了status&#x3D;12&#x2F;13的情况</p>
<p>status:</p>
<p><img  src="/./images/ky1012%5Cstatus%E4%B8%AD%E6%96%87.png"  ><span class="image-caption">status中文</span></p>
<p>错误原因：</p>
<p>![numerical issues](.&#x2F;images&#x2F;ky1012\numerical issues.png)</p>
<ol>
<li><p>建立模型时系数的舍入（四舍五入导致原有模型中自洽的约束冲突，一般很容易找）</p>
</li>
<li><p>浮点数运算限制</p>
</li>
<li><p>要求精度过高</p>
</li>
<li><p>其他数学原因</p>
<p>我的问题在于数值差过大，在gurobi中，x&lt;&#x3D;0和x&gt;&#x3D;10^（-10）是可以同时存在的，这种机制主要是为了避免计算时省略的n位小数带来的《最优解不被承认是最优解，因为它甚至不可行》。</p>
<p>但是这个机制会使得参数&#x2F;变量的最大值和最小值相差过大时导致数值错误（gurobi会试图找到解，这时status是13，有解，或者sataus是12，无解），大M法用的话有时候也会出现这样的问题。</p>
<p>改的办法的话：缩放数值太大或者太小的行，可以迭代。尽量用先验知识缩范围。</p>
</li>
</ol>
]]></content>
      <tags>
        <tag>优化</tag>
      </tags>
  </entry>
</search>
